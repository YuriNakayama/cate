{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch import Tensor\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from tqdm.notebook import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 乱数シード固定（再現性の担保）\n",
    "def fix_seed(seed) -> None:\n",
    "    # random\n",
    "    random.seed(seed)\n",
    "    # numpy\n",
    "    np.random.seed(seed)\n",
    "    # pytorch\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データローダーのサブプロセスの乱数seedが固定\n",
    "def worker_init_fn(worker_id) -> None:\n",
    "    np.random.seed(np.random.get_state()[1][0] + worker_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mydataset(Dataset):\n",
    "    def __init__(self, df, x_columns, y_columns) -> None:\n",
    "        self._df = df\n",
    "        self.x_columns = x_columns\n",
    "        self.y_columns = y_columns\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self._df.select(pl.len()).to_numpy()[0][0]\n",
    "\n",
    "    def __getitem__(self, idx) -> tuple[Tensor, Tensor]:\n",
    "        features = np.array(self._df.select(self.x_columns).row(idx)[:-1])\n",
    "        target = np.array(self._df.select(self.y_columns).row(idx)[-1])\n",
    "        return torch.tensor(features, dtype=torch.float32), torch.tensor(\n",
    "            target, dtype=torch.float32\n",
    "        )\n",
    "    @property\n",
    "    def y(self) -> Tensor:\n",
    "        return self._df.select(self.y_columns).to_torch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの定義\n",
    "class Mymodel(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, 3, 2, 1), nn.BatchNorm2d(16), nn.ReLU()\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 64, 3, 2, 1), nn.BatchNorm2d(64), nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.fc1 = nn.Linear(2 * 2 * 64, 100)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = torch.nn.Linear(100, 2)\n",
    "\n",
    "    def forward(self, x) -> Tensor:\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# リソースの指定（CPU/GPU）\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "seed = 42\n",
    "fix_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.read_csv(\"/workspace/data/origin/criteo.csv\")\n",
    "y_column = \"visit\"\n",
    "X_columns = df.columns.remove(y_column)\n",
    "dataset = Mydataset(df, X_columns, y_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[12.6164, 10.0597,  8.9764,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [12.6164, 10.0597,  9.0027,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [12.6164, 10.0597,  8.9648,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        ...,\n",
       "        [12.6164, 10.0597,  8.9422,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [24.5558, 10.0597,  8.2144,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [26.6716, 10.0597,  8.2144,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_torch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'to_tensor'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[68], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[63], line 17\u001b[0m, in \u001b[0;36mMydataset.y\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21my\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my_columns\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_tensor\u001b[49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'to_tensor'"
     ]
    }
   ],
   "source": [
    "dataset.y()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LazyFrame' object has no attribute 'to_numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[65], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m skf \u001b[38;5;241m=\u001b[39m StratifiedKFold(n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mseed)\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _fold, (train_index, valid_index) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(skf\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m))):\n\u001b[1;32m      3\u001b[0m     train_dataset \u001b[38;5;241m=\u001b[39m Subset(dataset, train_index)\n\u001b[1;32m      4\u001b[0m     valid_dataset \u001b[38;5;241m=\u001b[39m Subset(dataset, valid_index)\n",
      "Cell \u001b[0;32mIn[63], line 8\u001b[0m, in \u001b[0;36mMydataset.__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__len__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[0;32m----> 8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlen\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_numpy\u001b[49m()[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LazyFrame' object has no attribute 'to_numpy'"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "for _fold, (train_index, valid_index) in enumerate(skf.split(range(len(dataset)))):\n",
    "    train_dataset = Subset(dataset, train_index)\n",
    "    valid_dataset = Subset(dataset, valid_index)\n",
    "\n",
    "    # データローダーの作成\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=16,  # バッチサイズ\n",
    "        shuffle=True,  # データシャッフル\n",
    "        num_workers=2,  # 高速化\n",
    "        pin_memory=True,  # 高速化\n",
    "        worker_init_fn=worker_init_fn,\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=16,\n",
    "        shuffle=False,\n",
    "        num_workers=2,\n",
    "        pin_memory=True,\n",
    "        worker_init_fn=worker_init_fn,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデル・損失関数・最適化アルゴリスムの設定\n",
    "model = Mymodel().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "\n",
    "# モデル訓練関数\n",
    "def train_model(model, train_loader, test_loader):\n",
    "    # Train loop ----------------------------\n",
    "    model.train()  # 学習モードをオン\n",
    "    train_batch_loss = []\n",
    "    for data, label in train_loader:\n",
    "        # GPUへの転送\n",
    "        data, label = data.to(device), label.to(device)\n",
    "        # 1. 勾配リセット\n",
    "        optimizer.zero_grad()\n",
    "        # 2. 推論\n",
    "        output = model(data)\n",
    "        # 3. 誤差計算\n",
    "        loss = criterion(output, label)\n",
    "        # 4. 誤差逆伝播\n",
    "        loss.backward()\n",
    "        # 5. パラメータ更新\n",
    "        optimizer.step()\n",
    "        # train_lossの取得\n",
    "        train_batch_loss.append(loss.item())\n",
    "\n",
    "    # Test(val) loop ----------------------------\n",
    "    model.eval()  # 学習モードをオフ\n",
    "    test_batch_loss = []\n",
    "    with torch.no_grad():  # 勾配を計算なし\n",
    "        for data, label in test_loader:\n",
    "            data, label = data.to(device), label.to(device)\n",
    "            output = model(data)\n",
    "            loss = criterion(output, label)\n",
    "            test_batch_loss.append(loss.item())\n",
    "\n",
    "    return model, np.mean(train_batch_loss), np.mean(test_batch_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練の実行\n",
    "epoch = 100\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "\n",
    "for epoch in tqdm(range(epoch)):\n",
    "    model, train_l, test_l = train_model(model)\n",
    "    train_loss.append(train_l)\n",
    "    test_loss.append(test_loss)\n",
    "    # 10エポックごとにロスを表示\n",
    "    if epoch % 10 == 0:\n",
    "        print(\n",
    "            \"Train loss: {a:.3f}, Test loss: {b:.3f}\".format(\n",
    "                a=train_loss[-1], b=test_loss[-1]\n",
    "            )\n",
    "        )\n",
    "\n",
    "# 学習状況（ロス）の確認\n",
    "plt.plot(train_loss, label=\"train_loss\")\n",
    "plt.plot(test_loss, label=\"test_loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cate",
   "language": "python",
   "name": "cate"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
